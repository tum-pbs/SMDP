{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Diffusion Posterior Sampling with Gaussian Noise\n",
    "\n",
    "In this notebook, we optimize the initial state of the buoyancy-driven flow with obstacles simulation to match the final state of a simulation. We use diffusion posterior sampling, DPS, with Gaussian noise as described in https://openreview.net/forum?id=OnD9zGAGT0k Algorithm 1 with a pretrained DDPM diffusion model. "
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "125d35fe5b4bce6"
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "sys.path.append('github/smdp/buoyancy-flow') \n",
    "sys.path.append('github/smdp/buoyancy-flow/baselines/diffusion-posterior-sampling')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-02T14:58:35.633207274Z",
     "start_time": "2023-11-02T14:58:35.619979640Z"
    }
   },
   "id": "46ec1c37065e7637"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Load the testing dataset"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "4d9111a78b3e118e"
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-02 15:58:35.770202: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-11-02 15:58:35.867124: I tensorflow/core/util/port.cc:104] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2023-11-02 15:58:36.356161: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: :/usr/local/cuda-11.5/lib64:/usr/local/cuda-11.5/lib64\n",
      "2023-11-02 15:58:36.356214: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: :/usr/local/cuda-11.5/lib64:/usr/local/cuda-11.5/lib64\n",
      "2023-11-02 15:58:36.356218: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length: 5\n"
     ]
    }
   ],
   "source": [
    "import h5py\n",
    "\n",
    "# import dataloader\n",
    "from dataloader_multi import DataLoader\n",
    "\n",
    "file_test = 'github/smdp/buoyancy-flow/data/smoke_plumes_test_r0.h5'\n",
    "\n",
    "dataKeys = None      \n",
    "with h5py.File(file_test, 'r') as f:\n",
    "    dataKeys = list(f.keys())\n",
    "\n",
    "dataKeys = list(zip([file_test] * len(dataKeys), dataKeys))\n",
    "\n",
    "test_data = DataLoader([file_test], dataKeys, name='test', batchSize=1)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-02T14:58:38.534558177Z",
     "start_time": "2023-11-02T14:58:35.624946589Z"
    }
   },
   "id": "48af9deff3a71643"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Load the pretrained diffusion model\n",
    "Define the model architecture and load the pretrained weights. "
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "985c5f37196c881f"
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "from unet import Unet\n",
    "import torch\n",
    "\n",
    "# file path for stored weights\n",
    "weight_file = 'github/diffusion-posterior-sampling-backup/results/ddpm-model-flow-2s3jcppm-20.pt'\n",
    "\n",
    "model_spec = {'channels': 4,\n",
    "              'image_size': 64,\n",
    "              'data_shape': (4, 64, 64),\n",
    "              'dim' : 64,\n",
    "              'dim_mults' : (1, 2, 2, 4,)}\n",
    "\n",
    "\n",
    "model = Unet(**model_spec)\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "data = torch.load(weight_file,\n",
    "                  map_location=device)\n",
    "model.load_state_dict(data['model'])\n",
    "model = model.to(device)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-02T14:58:41.077367132Z",
     "start_time": "2023-11-02T14:58:38.532171587Z"
    }
   },
   "id": "9c9bd97c73926030"
  },
  {
   "cell_type": "markdown",
   "source": [
    "Load LPIPS for perceptual distance metric"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "587ff780166fa5b9"
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/benjamin/anaconda3/envs/smdp/lib/python3.8/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/home/benjamin/anaconda3/envs/smdp/lib/python3.8/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=AlexNet_Weights.IMAGENET1K_V1`. You can also use `weights=AlexNet_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model from: /home/benjamin/anaconda3/envs/smdp/lib/python3.8/site-packages/lpips/weights/v0.1/alex.pth\n"
     ]
    }
   ],
   "source": [
    "# import LPIPS distance\n",
    "import evaluation.lpips as lpips"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-02T14:58:41.958796909Z",
     "start_time": "2023-11-02T14:58:41.080738586Z"
    }
   },
   "id": "17db5bd39e1666e8"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Optimization with DPS\n",
    "First, define all hyperparameters and simulation environment"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "31e6edaaa0b32ec1"
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "# simulation time of initial state to be optimized\n",
    "time_init = 35 # t=0.35\n",
    "\n",
    "# diffusion posterior sampling parameter for scaling the gradient\n",
    "zeta = 1.0\n",
    "\n",
    "# inference time step to start optimizing (default: 0)\n",
    "dps_optim_start = 0\n",
    "\n",
    "params = {\n",
    "    'batch_size' : 1,\n",
    "    'DT' : 0.01,\n",
    "    't1': 0.65,\n",
    "    'time_init': time_init,\n",
    "    'zeta': zeta,\n",
    "    'image_channels' : 4,\n",
    "    'image_size' : 64,\n",
    "    'dps_optim_start' : dps_optim_start\n",
    "}"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-02T14:58:41.964224522Z",
     "start_time": "2023-11-02T14:58:41.961696452Z"
    }
   },
   "id": "3123adcb93c1b8e9"
  },
  {
   "cell_type": "markdown",
   "source": [
    "Define optimization with DPS, Algorithm 1, Gaussian noise"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "ec8cf1a9cc76faf6"
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "from physics_check import batch_inflow, physics_forward, batch_geometries_pre_phiflow\n",
    "from eval import eval_forward   \n",
    "from phi.torch.flow import *\n",
    "from sample import gather\n",
    "from tqdm import tqdm\n",
    "\n",
    "def optimize_sample(item, params):\n",
    "\n",
    "    simulation_metadata = {}\n",
    "    simulation_metadata['NSTEPS'] = int(params['t1'] / params['DT'])\n",
    "    simulation_metadata['INFLOW'] = batch_inflow(item['INFLOW'], batchSize=params['batch_size'])\n",
    "    simulation_metadata['INFLOW_1b'] = batch_inflow(item['INFLOW'], batchSize=1)\n",
    "    bounds = item['BOUNDS']\n",
    "    simulation_metadata['BOUNDS'] = Box(x=(bounds['_lower'][0], bounds['_upper'][0]),\n",
    "                                        y=(bounds['_lower'][1], bounds['_upper'][1]))\n",
    "    simulation_metadata['smoke_res'] = item['smoke_res']\n",
    "    simulation_metadata['v_res'] = item['v_res']\n",
    "    simulation_metadata['DT'] = params['DT']\n",
    "\n",
    "    obstacles = [item['obstacle_list']]\n",
    "    obstacles = batch_geometries_pre_phiflow(obstacles)\n",
    "\n",
    "    smoke_state = torch.asarray(item['smoke'], dtype=torch.float32)\n",
    "    vel_x_state = torch.asarray(item['vel_x'], dtype=torch.float32)\n",
    "    vel_y_state = torch.asarray(item['vel_y'], dtype=torch.float32)\n",
    "    mask_state = torch.asarray(item['mask'], dtype=torch.float32).to(device)\n",
    "\n",
    "    init_state = [smoke_state[0][None], vel_x_state[0][None], vel_y_state[0][None], mask_state[0][None]]\n",
    "    target_state = [smoke_state[-1][None].to('cuda:0'), vel_x_state[-1][None].to('cuda:0'),\n",
    "                    vel_y_state[-1][None].to('cuda:0')]\n",
    "\n",
    "    forward_fn = physics_forward(simulation_metadata)\n",
    "    forward_fn = math.jit_compile(forward_fn)\n",
    "\n",
    "    t0 = 0.64\n",
    "    simulation_metadata['NSTEPS'] = int((params['t1'] - t0) / params['DT'])\n",
    "    _ = eval_forward(init_state, obstacles, simulation_metadata, physics_forward_fn=forward_fn, t0=t0)\n",
    "    \n",
    "    def loss_function(init_state_):\n",
    "\n",
    "        t0 = params['time_init'] * params['DT']\n",
    "\n",
    "        init_state_.append(torch.zeros_like(init_state[3]).clone().detach().requires_grad_(False))\n",
    "\n",
    "        simulation_metadata['NSTEPS'] = int((params['t1'] - t0) / params['DT'])\n",
    "\n",
    "        out = eval_forward(init_state_, obstacles, simulation_metadata, physics_forward_fn=forward_fn, t0=t0)\n",
    "\n",
    "        smoke_out = out[-1][0][0]\n",
    "        vel_x_out = out[-1][1][0]\n",
    "        vel_y_out = out[-1][2][0]\n",
    "\n",
    "        smoke_target = target_state[0][0]\n",
    "        vel_x_target = target_state[1][0]\n",
    "        vel_y_target = target_state[2][0]\n",
    "\n",
    "        norm = torch.linalg.norm(smoke_target - smoke_out) + torch.linalg.norm(\n",
    "            vel_x_target - vel_x_out) + torch.linalg.norm(vel_y_target - vel_y_out)\n",
    "\n",
    "        return torch.nn.functional.mse_loss(smoke_target, smoke_out) + torch.nn.functional.mse_loss(vel_x_target,\n",
    "                                                                                                    vel_x_out) + torch.nn.functional.mse_loss(\n",
    "            vel_y_target, vel_y_out), norm\n",
    "\n",
    "\n",
    "    image_channels = params['image_channels']\n",
    "    image_size = params['image_size']\n",
    "    \n",
    "    n_steps = 1000\n",
    "    beta = torch.linspace(0.0001, 0.02, 1000).to(device)\n",
    "    alpha = 1. - beta\n",
    "    alpha_bar = torch.cumprod(alpha, dim=0)\n",
    "    sigma2 = beta\n",
    "\n",
    "    x = torch.randn([1, image_channels, image_size, image_size],\n",
    "                    device=mask_state[:1].device)\n",
    "\n",
    "    x[:, 0] = mask_state[:1]\n",
    "\n",
    "    zeta_scale = params['zeta']\n",
    "\n",
    "    pbar = tqdm(range(n_steps - 1))\n",
    "\n",
    "    cutoff = params['dps_optim_start']\n",
    "\n",
    "    for t_ in pbar:\n",
    "        \n",
    "        t = n_steps - t_ - 1\n",
    "        t_m1 = t - 1\n",
    "        t_in = x.new_full((1,), t, dtype=torch.long)\n",
    "        t_in_m1 = x.new_full((1,), t_m1, dtype=torch.long)\n",
    "        alpha_bar_t = gather(alpha_bar, t_in)\n",
    "        alpha_bar_t_m1 = gather(alpha_bar, t_in_m1)\n",
    "        alpha_t = gather(alpha, t_in)\n",
    "        beta_t = gather(beta, t_in)\n",
    "        var_t = gather(sigma2, t_in)\n",
    "        eps = torch.randn(x.shape, device=x.device)\n",
    "\n",
    "        x_grad_leaf = x.clone().detach().requires_grad_(True)\n",
    "\n",
    "        if t_ > cutoff:\n",
    "\n",
    "            s_hat = model(x_grad_leaf, t_in) / ((1 - alpha_bar_t) ** 0.5)\n",
    "            x_hat_0 = (1 / (alpha_bar_t ** 0.5)) * (x_grad_leaf - (1 - alpha_bar_t) * s_hat)\n",
    "\n",
    "            x_dash = (((alpha_t ** 0.5) * (1 - alpha_bar_t_m1)) / (1 - alpha_bar_t)) * x_grad_leaf\n",
    "            x_dash = x_dash + (((alpha_bar_t_m1 ** 0.5) * beta_t) / (1 - alpha_bar_t)) * x_hat_0\n",
    "            x_dash = x_dash + (var_t ** .5) * eps\n",
    "\n",
    "            smoke_state_ = x_hat_0[:, 1]\n",
    "            vel_x_state_ = x_hat_0[:, 2][:, :, :63]\n",
    "            vel_y_state_ = x_hat_0[:, 3][:, :63, :]\n",
    "\n",
    "            l, norm = loss_function([smoke_state_, vel_x_state_, vel_y_state_])\n",
    "            l.backward()\n",
    "\n",
    "            pbar.set_description(\"Loss: %s\" % l.item())\n",
    "\n",
    "            gradient_to_leaf = x_grad_leaf.grad[0]\n",
    "\n",
    "            x = x_dash - zeta_scale * gradient_to_leaf * 1 / norm  # did not find scaling by norm in reference implementation by authors\n",
    "\n",
    "        else:\n",
    "\n",
    "            eps_theta = model(x_grad_leaf, t_in)\n",
    "            eps_coef = (1 - alpha_t) / (1 - alpha_bar_t) ** .5\n",
    "            mean = 1 / (alpha_t ** 0.5) * (x_grad_leaf - eps_coef * eps_theta)\n",
    "            x_grad = mean + (var_t ** .5) * eps\n",
    "            x = x_grad\n",
    "\n",
    "        x[:, 0] = mask_state[:1]\n",
    "        # pytorch clear cache\n",
    "        torch.cuda.empty_cache()\n",
    "        \n",
    "    smoke_state_final = x[:, 1]\n",
    "    vel_x_state_final = x[:, 2][:, :, :63]\n",
    "    vel_y_state_final = x[:, 3][:, :63, :]\n",
    "        \n",
    "    state_final = [smoke_state_final, vel_x_state_final, vel_y_state_final, mask_state[0][None]]\n",
    "        \n",
    "    prediction = eval_forward(state_final, obstacles, simulation_metadata, \n",
    "                              physics_forward_fn=forward_fn, t0=params['time_init']*params['DT'])\n",
    "    \n",
    "    return [(marker_field.detach().cpu().numpy(), vel_x_field.detach().cpu().numpy(), \n",
    "             vel_y_field.detach().cpu().numpy(), mask_field.detach().cpu().numpy()) \n",
    "            for marker_field, vel_x_field, vel_y_field, mask_field in prediction]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-02T14:58:42.315994874Z",
     "start_time": "2023-11-02T14:58:41.979318816Z"
    }
   },
   "id": "bafa43a159eef78e"
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "jit compile physics\n",
      "tracing physics forwards...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/benjamin/anaconda3/envs/smdp/lib/python3.8/site-packages/phi/torch/_torch_backend.py:731: UserWarning: Sparse CSR tensor support is in beta state. If you miss a functionality in the sparse tensor support, please submit a feature request to https://github.com/pytorch/pytorch/issues. (Triggered internally at ../aten/src/ATen/SparseCsrTensorImpl.cpp:54.)\n",
      "  return torch.sparse_csr_tensor(row_pointers, column_indices, values, shape, device=values.device)\n",
      "/home/benjamin/anaconda3/envs/smdp/lib/python3.8/site-packages/phi/torch/_torch_backend.py:57: TracerWarning: torch.from_numpy results are registered as constants in the trace. You can safely ignore this warning if you use this function to create tensors out of constant variables that would be the same every time you call this function. In any other case, this might cause the trace to be incorrect.\n",
      "  tensor = torch.from_numpy(x)\n",
      "/home/benjamin/anaconda3/envs/smdp/lib/python3.8/site-packages/phi/torch/_torch_backend.py:731: TracerWarning: torch.sparse_csr_tensor results are registered as constants in the trace. You can safely ignore this warning if you use this function to create tensors out of constant variables that would be the same every time you call this function. In any other case, this might cause the trace to be incorrect.\n",
      "  return torch.sparse_csr_tensor(row_pointers, column_indices, values, shape, device=values.device)\n",
      "/home/benjamin/anaconda3/envs/smdp/lib/python3.8/site-packages/phi/torch/_torch_backend.py:573: TracerWarning: Converting a tensor to a Python integer might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  return tuple([int(s) for s in tensor.shape])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tracing physics forwards...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/benjamin/anaconda3/envs/smdp/lib/python3.8/site-packages/phi/torch/_torch_backend.py:69: TracerWarning: torch.tensor results are registered as constants in the trace. You can safely ignore this warning if you use this function to create tensors out of constant variables that would be the same every time you call this function. In any other case, this might cause the trace to be incorrect.\n",
      "  tensor = torch.tensor(x, device=self.get_default_device().ref)\n",
      "/home/benjamin/anaconda3/envs/smdp/lib/python3.8/site-packages/phi/torch/_torch_backend.py:310: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  if coordinates.shape[0] != grid.shape[0]:  # repeating yields wrong result\n",
      "/home/benjamin/anaconda3/envs/smdp/lib/python3.8/site-packages/phi/torch/_torch_backend.py:316: TracerWarning: torch.tensor results are registered as constants in the trace. You can safely ignore this warning if you use this function to create tensors out of constant variables that would be the same every time you call this function. In any other case, this might cause the trace to be incorrect.\n",
      "  resolution = torch.tensor(self.staticshape(grid)[2:], dtype=coordinates.dtype, device=coordinates.device)\n",
      "/home/benjamin/anaconda3/envs/smdp/lib/python3.8/site-packages/phi/math/backend/_backend.py:1694: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  if dim1 is None or dim1 == 1:\n",
      "/home/benjamin/anaconda3/envs/smdp/lib/python3.8/site-packages/phi/torch/_torch_backend.py:320: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  coordinates = coordinates.repeat(batch_size, *[1] * (len(coordinates.shape-1))) if coordinates.shape[0] < batch_size else coordinates\n",
      "/home/benjamin/anaconda3/envs/smdp/lib/python3.8/site-packages/phi/torch/_torch_backend.py:321: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  grid = grid.repeat(batch_size, *[1] * (len(grid.shape)-1)) if grid.shape[0] < batch_size else grid\n",
      "/home/benjamin/anaconda3/envs/smdp/lib/python3.8/site-packages/phi/torch/_torch_backend.py:592: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  b_indices = self.unstack(indices[min(b, indices.shape[0] - 1)], -1)\n",
      "/home/benjamin/anaconda3/envs/smdp/lib/python3.8/site-packages/phi/torch/_torch_backend.py:593: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  result.append(values[(min(b, values.shape[0] - 1),) + b_indices])\n",
      "Loss: 2.4086344242095947: 100%|███████████████| 999/999 [00:36<00:00, 27.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "jit compile physics\n",
      "tracing physics forwards...\n",
      "tracing physics forwards...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 2.4835853576660156: 100%|███████████████| 999/999 [00:28<00:00, 35.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "jit compile physics\n",
      "tracing physics forwards...\n",
      "tracing physics forwards...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 1.5106109380722046: 100%|███████████████| 999/999 [00:28<00:00, 34.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "jit compile physics\n",
      "tracing physics forwards...\n",
      "tracing physics forwards...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 1.1385670900344849: 100%|███████████████| 999/999 [00:30<00:00, 32.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "jit compile physics\n",
      "tracing physics forwards...\n",
      "tracing physics forwards...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.8904870748519897: 100%|███████████████| 999/999 [00:28<00:00, 35.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reconstruction MSE:  0.7691944122314454\n",
      "LPIPS smoke:  0.09035247787833214\n"
     ]
    }
   ],
   "source": [
    "results = {}\n",
    "\n",
    "reconstruction_MSE = 0\n",
    "lpips_smoke = 0\n",
    "\n",
    "for key in dataKeys:\n",
    "\n",
    "    item = test_data.load(key)\n",
    "\n",
    "    prediction = optimize_sample(item, params)\n",
    "\n",
    "    results[key] = prediction   \n",
    "\n",
    "    smoke_state = torch.asarray(item['smoke'], dtype=torch.float32)\n",
    "\n",
    "    reconstruction_MSE += torch.nn.functional.mse_loss(torch.tensor(prediction[-1][0][0]), smoke_state[-1]).item()\n",
    "\n",
    "    lpips_smoke += lpips.lpips_dist(prediction[0][0], smoke_state[time_init][None].numpy())\n",
    "\n",
    "lpips_smoke = lpips_smoke / len(dataKeys)\n",
    "reconstruction_MSE = reconstruction_MSE / len(dataKeys)\n",
    "\n",
    "print('Reconstruction MSE: ', reconstruction_MSE)\n",
    "print('LPIPS smoke: ', lpips_smoke)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-02T15:01:47.156365113Z",
     "start_time": "2023-11-02T14:58:42.320416853Z"
    }
   },
   "id": "9ae8e605dfcfb302"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Save results"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "104fbab66d5cb95e"
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [],
   "source": [
    "# save results to file\n",
    "import pickle   \n",
    "\n",
    "results_file = 'github/smdp/buoyancy-flow/evaluation/results/results_dps.pkl'\n",
    "\n",
    "with open(results_file, 'wb') as f:\n",
    "    pickle.dump(results, f)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-02T15:20:59.782330871Z",
     "start_time": "2023-11-02T15:20:59.746628255Z"
    }
   },
   "id": "b5e7d4412c32128b"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "e6ee7a7630d9552c"
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "smdp",
   "language": "python",
   "display_name": "smdp"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
